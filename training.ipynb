{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77bc5a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import TrainingArguments\n",
    "from Geneformer.geneformer import Classifier\n",
    "from Geneformer.geneformer import TranscriptomeTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419cf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset/CD4_prepped.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:02<00:00,  6.64it/s]\n",
      "/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/anndata/_core/merge.py:1434: UserWarning: Only some AnnData objects have `.raw` attribute, not concatenating `.raw` attributes.\n",
      "  warn(\n",
      "/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/anndata/_core/anndata.py:787: ImplicitModificationWarning: Trying to modify index of attribute `.obs` of view, initializing view as actual.\n",
      "  getattr(self, attr).index = value\n",
      "/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/anndata/_core/anndata.py:1758: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/c4/home/tagashe/jdmwork/Geneformer/geneformer/tokenizer.py:511: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\n",
      "/c4/home/tagashe/jdmwork/Geneformer/geneformer/tokenizer.py:514: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coding_miRNA_ids = adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/CD4_prepped.h5ad has no column attribute 'filter_pass'; tokenizing all cells.\n",
      "Creating dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tk = TranscriptomeTokenizer(\n",
    "#   custom_attr_name_dict={\n",
    "#     \"disease_group\": \"disease_group\",\n",
    "#     # \"sex\": \"sex\",\n",
    "#     # \"self_reported_ethnicity\": \"self_reported_ethnicity\",\n",
    "#     \"donor_id\": \"donor_id\",\n",
    "#     # \"observation_joinid\": \"observation_joinid\"\n",
    "#   },\n",
    "#   nproc=16\n",
    "# )\n",
    "\n",
    "\n",
    "# tk.tokenize_data(\n",
    "#     \"dataset\",\n",
    "#     \"tokenized_dataset\",\n",
    "#     \"tokenized\",\n",
    "#     file_format = \"h5ad\"  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa59364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "import os\n",
    "\n",
    "input_data_folder = os.path.abspath(\"tokenized_dataset/tokenized.dataset\")\n",
    "prepared_data_folder = os.path.abspath(\"CD4_finetune_prepared\")\n",
    "results_folder = os.path.abspath(\"CD4_finetune_results\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "      num_train_epochs=1,              \n",
    "      learning_rate=5e-5,\n",
    "      per_device_train_batch_size=12,\n",
    "      lr_scheduler_type='polynomial',\n",
    "      warmup_steps=50,\n",
    "      weight_decay=0.01,\n",
    "      skip_memory_metrics=True,\n",
    "      report_to=\"none\",                  # Avoid logging integrations\n",
    "      save_strategy=\"no\",                # Don't try to save model checkpoints (avoids\n",
    "      seed=73,\n",
    "  )\n",
    "\n",
    "# training_args = {\n",
    "#     \"num_train_epochs\": 0.9,\n",
    "#     \"learning_rate\": 0.000804,\n",
    "#     \"lr_scheduler_type\": \"polynomial\",\n",
    "#     \"warmup_steps\": 1812,\n",
    "#     \"weight_decay\":0.258828,\n",
    "#     \"per_device_train_batch_size\": 1,\n",
    "#     \"seed\": 73,\n",
    "# }\n",
    "\n",
    "model = Classifier(\n",
    "      classifier=\"cell\",\n",
    "      cell_state_dict={\"state_key\": \"disease_group\", \"states\": \"all\"},\n",
    "      max_ncells=100,                  \n",
    "      training_args=training_args.to_dict(),\n",
    "      freeze_layers=4,                 \n",
    "      num_crossval_splits=1,           # no cross-validation\n",
    "      forward_batch_size=64,\n",
    "      nproc=8,\n",
    "      model_version=\"V2\")\n",
    "\n",
    "os.makedirs(prepared_data_folder, exist_ok=True)\n",
    "os.makedirs(results_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f22990",
   "metadata": {},
   "source": [
    "0\tHC16\n",
    "1\tHC17\n",
    "2\tHC18\n",
    "3\tHC19\n",
    "4\tHC20\n",
    "5\tJDM1\n",
    "6\tJDM10\n",
    "7\tJDM11\n",
    "8\tJDM12\n",
    "9\tJDM13\n",
    "10\tJDM14\n",
    "11\tJDM15\n",
    "12\tJDM2\n",
    "13\tJDM3\n",
    "14\tJDM4\n",
    "15\tJDM5\n",
    "16\tJDM6\n",
    "17\tJDM7\n",
    "18\tJDM8\n",
    "19\tJDM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10351c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [5, 9, 14, 17, 4, 10, 1, 12, 0, 15, 19, 16, 12, 14, 5, 9] # all cases ( 3 HCs, 6 TNJDM, 3 Active, 4 Inactive)\n",
    "eval_ids = [6, 7, 3, 11] # 1 case each\n",
    "test_ids = [2, 8, 13, 18] # 1 case each \n",
    "\n",
    "train_test_id_split_dict = {\"attr_key\": \"donor_id\",\n",
    "                            \"train\": train_ids+eval_ids,\n",
    "                            \"test\": test_ids}\n",
    "\n",
    "\n",
    "model.prepare_data(\n",
    "      input_data_file=input_data_folder,\n",
    "      output_directory=prepared_data_folder,\n",
    "      output_prefix=\"jdm\",\n",
    "      split_id_dict=train_test_id_split_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0e2ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜/c4/home/tagashe/jdmwork/CD4_finetune_results/250627_geneformer_cellClassifier_jdm_classifier/â€™: File exists\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation split: 1/1 ******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 15:33:46,498\tINFO worker.py:1917 -- Started a local Ray instance.\n",
      "mkdir: cannot create directory â€˜/c4/home/tagashe/jdmwork/CD4_finetune_results/250627_geneformer_cellClassifier_jdm_classifier/ksplit1â€™: File exists\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /c4/home/tagashe/jdmwork/Geneformer/Geneformer-V2-104M and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/training_args.py:2080: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /c4/home/tagashe/jdmwork/Geneformer/Geneformer-V2-104M and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No ray_config provided. Proceeding with default, but ranges may need adjustment depending on model.\n",
      "2025-06-27 15:33:51,237\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-06-27 15:33:51,315\tWARNING callback.py:136 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-27 15:33:51 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/104 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /scratch/tagashe/ray/session_2025-06-27_15-33-39_782521_1168859/artifacts/2025-06-27_15-33-51/_objective_2025-06-27_15-33-51/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_objective pid=1347034)\u001b[0m /c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/train/_internal/session.py:834: RayDeprecationWarning: `ray.train.get_checkpoint` should be switched to `ray.tune.get_checkpoint` when running in a function passed to Ray Tune. This will be an error in the future. See this issue for more context: https://github.com/ray-project/ray/issues/49454\n",
      "\u001b[36m(_objective pid=1347034)\u001b[0m   _log_deprecation_warning(\n",
      "\u001b[36m(_objective pid=1347034)\u001b[0m Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[36m(_objective pid=1347034)\u001b[0m Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /c4/home/tagashe/jdmwork/Geneformer/Geneformer-V2-104M and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "\u001b[36m(_objective pid=1347034)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]/c4/home/tagashe/jdmwork/Geneformer/geneformer/collator_for_classification.py:649: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[36m(_objective pid=1347034)\u001b[0m   batch = {k: torch.tensor(v.clone().detach(), dtype=torch.int64) if isinstance(v, torch.Tensor) else torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n",
      "2025-06-27 15:34:40,428\tERROR tune_controller.py:1331 -- Trial task failed for trial _objective_acb63b42\n",
      "Traceback (most recent call last):\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 22, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 104, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/_private/worker.py\", line 2849, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/_private/worker.py\", line 937, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(OutOfMemoryError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1347034, ip=169.230.134.166, actor_id=5e9bac1d555df5ec1f2680e601000000, repr=_objective)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 330, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/air/_internal/util.py\", line 107, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 261, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/integrations/integration_utils.py\", line 410, in dynamic_modules_import_trainable\n",
      "    return trainable(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/integrations/integration_utils.py\", line 323, in _objective\n",
      "    local_trainer.train(trial=trial)\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/trainer.py\", line 2207, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/trainer.py\", line 2549, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/trainer.py\", line 3750, in training_step\n",
      "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/trainer.py\", line 3837, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 1483, in forward\n",
      "    outputs = self.bert(\n",
      "              ^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 996, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 651, in forward\n",
      "    layer_outputs = layer_module(\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/modeling_layers.py\", line 83, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 553, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 492, in forward\n",
      "    attention_output = self.output(self_outputs[0], hidden_states)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 435, in forward\n",
      "    hidden_states = self.dropout(hidden_states)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n",
      "    return F.dropout(input, self.p, self.training, self.inplace)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/c4/home/tagashe/jdmwork/jdmproject/lib64/python3.11/site-packages/torch/nn/functional.py\", line 1425, in dropout\n",
      "    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 15.72 GiB of which 13.88 MiB is free. Process 2590501 has 472.00 MiB memory in use. Process 3703903 has 260.00 MiB memory in use. Process 3247121 has 1.37 GiB memory in use. Process 1168859 has 1.01 GiB memory in use. Including non-PyTorch memory, this process has 12.61 GiB memory in use. Of the allocated memory 12.18 GiB is allocated by PyTorch, and 245.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_objective_acb63b42</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 15:34:40,470\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/c4/home/tagashe/jdmwork/CD4_finetune_results/250627_geneformer_cellClassifier_jdm_classifier/ksplit1/_objective_2025-06-27_15-33-51' in 0.0332s.\n",
      "  0%|          | 0/1 [01:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-27 15:34:40 (running for 00:00:49.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 8.0/104 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:RTX)\n",
      "Result logdir: /scratch/tagashe/ray/session_2025-06-27_15-33-39_782521_1168859/artifacts/2025-06-27_15-33-51/_objective_2025-06-27_15-33-51/driver_artifacts\n",
      "Number of trials: 1/1 (1 ERROR)\n",
      "+---------------------+----------+-------------------------+-----------------+---------------------+--------------------+------------------------+---------+----------------+----------------+\n",
      "| Trial name          | status   | loc                     |   learning_rate | lr_scheduler_type   |   num_train_epochs |   per_device_train_bat |    seed |   warmup_steps |   weight_decay |\n",
      "|                     |          |                         |                 |                     |                    |                ch_size |         |                |                |\n",
      "|---------------------+----------+-------------------------+-----------------+---------------------+--------------------+------------------------+---------+----------------+----------------|\n",
      "| _objective_acb63b42 | ERROR    | 169.230.134.166:1347034 |     2.04682e-05 | cosine              |                  1 |                     12 | 41.5765 |        1782.08 |       0.156172 |\n",
      "+---------------------+----------+-------------------------+-----------------+---------------------+--------------------+------------------------+---------+----------------+----------------+\n",
      "Number of errored trials: 1\n",
      "+---------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Trial name          |   # failures | error file                                                                                                                                                                                                                                                                                                     |\n",
      "|---------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| _objective_acb63b42 |            1 | /scratch/tagashe/ray/session_2025-06-27_15-33-39_782521_1168859/artifacts/2025-06-27_15-33-51/_objective_2025-06-27_15-33-51/driver_artifacts/_objective_acb63b42_1_learning_rate=0.0000,lr_scheduler_type=cosine,num_train_epochs=1,per_device_train_batch_size=12,seed=41.5765_2025-06-27_15-33-51/error.txt |\n",
      "+---------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [_objective_acb63b42])",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTuneError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m train_valid_id_split_dict = {\u001b[33m\"\u001b[39m\u001b[33mattr_key\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mdonor_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      2\u001b[39m                             \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m: train_ids,\n\u001b[32m      3\u001b[39m                             \u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m: eval_ids}\n\u001b[32m      5\u001b[39m model_path = os.path.abspath(\u001b[33m\"\u001b[39m\u001b[33m./Geneformer/Geneformer-V2-104M\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m metrics = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprepared_input_data_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprepared_data_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/jdm_labeled_train.dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mid_class_dict_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprepared_data_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/jdm_id_class_dict.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjdm_classifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_id_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_valid_id_split_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_hyperopt_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/Geneformer/geneformer/classifier.py:823\u001b[39m, in \u001b[36mClassifier.validate\u001b[39m\u001b[34m(self, model_directory, prepared_input_data_file, id_class_dict_file, output_directory, output_prefix, split_id_dict, attr_to_split, attr_to_balance, gene_balance, max_trials, pval_threshold, save_eval_output, predict_eval, predict_trainer, n_hyperopt_trials, save_gene_split_datasets, debug_gene_split_datasets)\u001b[39m\n\u001b[32m    814\u001b[39m     trainer = \u001b[38;5;28mself\u001b[39m.train_classifier(\n\u001b[32m    815\u001b[39m         model_directory,\n\u001b[32m    816\u001b[39m         num_classes,\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m         predict_trainer,\n\u001b[32m    821\u001b[39m     )\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     trainer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhyperopt_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43mksplit_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_hyperopt_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    831\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m iteration_num == \u001b[38;5;28mself\u001b[39m.num_crossval_splits:\n\u001b[32m    832\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/Geneformer/geneformer/classifier.py:1159\u001b[39m, in \u001b[36mClassifier.hyperopt_classifier\u001b[39m\u001b[34m(self, model_directory, num_classes, train_data, eval_data, output_directory, n_trials)\u001b[39m\n\u001b[32m   1156\u001b[39m hyperopt_search = HyperOptSearch(metric=\u001b[33m\"\u001b[39m\u001b[33meval_macro_f1\u001b[39m\u001b[33m\"\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1158\u001b[39m \u001b[38;5;66;03m# optimize hyperparameters\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mray\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresources_per_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnproc\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mngpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhp_space\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdef_ray_config\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mray_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mray_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperopt_search\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# number of trials\u001b[39;49;00m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_reporter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCLIReporter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_report_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort_by_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_progress_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_macro_f1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mloss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_accuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_macro_f1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/trainer.py:3634\u001b[39m, in \u001b[36mTrainer.hyperparameter_search\u001b[39m\u001b[34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[39m\n\u001b[32m   3631\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_name = hp_name\n\u001b[32m   3632\u001b[39m \u001b[38;5;28mself\u001b[39m.compute_objective = default_compute_objective \u001b[38;5;28;01mif\u001b[39;00m compute_objective \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m compute_objective\n\u001b[32m-> \u001b[39m\u001b[32m3634\u001b[39m best_run = \u001b[43mbackend_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3636\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_search_backend = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m best_run\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/hyperparameter_search.py:87\u001b[39m, in \u001b[36mRayTuneBackend.run\u001b[39m\u001b[34m(self, trainer, n_trials, direction, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer, n_trials: \u001b[38;5;28mint\u001b[39m, direction: \u001b[38;5;28mstr\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_hp_search_ray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/jdmproject/lib64/python3.11/site-packages/transformers/integrations/integration_utils.py:416\u001b[39m, in \u001b[36mrun_hp_search_ray\u001b[39m\u001b[34m(trainer, n_trials, direction, **kwargs)\u001b[39m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trainable, \u001b[33m\"\u001b[39m\u001b[33m__mixins__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    414\u001b[39m     dynamic_modules_import_trainable.__mixins__ = trainable.__mixins__\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m analysis = \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdynamic_modules_import_trainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhp_space\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    422\u001b[39m best_trial = analysis.get_best_trial(metric=\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m, mode=direction[:\u001b[32m3\u001b[39m], scope=trainer.args.ray_scope)\n\u001b[32m    423\u001b[39m best_run = BestRun(best_trial.trial_id, best_trial.last_result[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m], best_trial.config, analysis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/jdmproject/lib64/python3.11/site-packages/ray/tune/tune.py:1035\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[39m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[32m   1034\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event.is_set():\n\u001b[32m-> \u001b[39m\u001b[32m1035\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[33m\"\u001b[39m\u001b[33mTrials did not complete\u001b[39m\u001b[33m\"\u001b[39m, incomplete_trials)\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1037\u001b[39m         logger.error(\u001b[33m\"\u001b[39m\u001b[33mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[31mTuneError\u001b[39m: ('Trials did not complete', [_objective_acb63b42])"
     ]
    }
   ],
   "source": [
    "train_valid_id_split_dict = {\"attr_key\": \"donor_id\",\n",
    "                            \"train\": train_ids,\n",
    "                            \"eval\": eval_ids}\n",
    "\n",
    "model_path = os.path.abspath(\"./Geneformer/Geneformer-V2-104M\")\n",
    "\n",
    "metrics = model.validate(\n",
    "        model_directory=model_path,\n",
    "        prepared_input_data_file=f\"{prepared_data_folder}/jdm_labeled_train.dataset\",\n",
    "        id_class_dict_file=f\"{prepared_data_folder}/jdm_id_class_dict.pkl\",\n",
    "        output_directory=results_folder,\n",
    "        output_prefix=\"jdm_classifier\",\n",
    "        split_id_dict=train_valid_id_split_dict,\n",
    "        n_hyperopt_trials=1    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163577a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conf_matrix':      0    1    2    3\n",
       " 0  2.0  0.0  1.0  0.0\n",
       " 1  6.0  0.0  1.0  0.0\n",
       " 2  2.0  0.0  1.0  0.0\n",
       " 3  0.0  0.0  0.0  0.0,\n",
       " 'macro_f1': [0.21367521367521367],\n",
       " 'acc': [0.23076923076923078],\n",
       " 'all_roc_metrics': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jdmproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
