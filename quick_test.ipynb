{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5531101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/c4/home/tagashe/jdmanalysis/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "from Geneformer.geneformer import Classifier, TranscriptomeTokenizer\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca8c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tk = TranscriptomeTokenizer(\n",
    "#         custom_attr_name_dict={\n",
    "#             \"disease_group\": \"disease_group\",\n",
    "#         },\n",
    "#         nproc=16  # adjust based on your system\n",
    "#     )\n",
    "\n",
    "# tk.tokenize_data(\n",
    "#     \"train_dataset\",\n",
    "#     \"tokenized_train_dataset\",\n",
    "#     \"tokenized\",\n",
    "#     file_format = \"h5ad\"  \n",
    "# )\n",
    "\n",
    "# tk.tokenize_data(\n",
    "#     \"test_dataset\",\n",
    "#     \"tokenized_test_dataset\",\n",
    "#     \"tokenized\",\n",
    "#     file_format = \"h5ad\"  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d163406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUNNING QUICK TEST WITH CORRECT API ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RUNNING QUICK TEST WITH CORRECT API ===\")\n",
    "    \n",
    "# Load and subset data\n",
    "full_dataset = load_from_disk(\"tokenized_train_dataset/tokenized.dataset\")\n",
    "subset = full_dataset.select(range(100))  # slightly more for meaningful test\n",
    "subset = subset.remove_columns('length')\n",
    "subset_path = \"tokenized_train_dataset/subset_test.dataset\"\n",
    "subset.save_to_disk(subset_path)\n",
    "\n",
    "os.makedirs(\"quick_test_output\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85ad11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>disease_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 18875, 9387, 16079, 13985, 7126, 16450, 66...</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 9217, 14319, 14806, 11632, 7716, 3495, 726...</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 5788, 15343, 12186, 7590, 8735, 3857, 1701...</td>\n",
       "      <td>TNJDM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 915, 4305, 11429, 9572, 15371, 1001, 241, ...</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 16736, 15270, 12350, 744, 4331, 3174, 4155...</td>\n",
       "      <td>TNJDM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[2, 5147, 11990, 17364, 11054, 13685, 5365, 15...</td>\n",
       "      <td>TNJDM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[2, 10643, 10673, 6331, 5689, 15032, 3462, 162...</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[2, 5301, 1815, 18787, 14578, 12978, 7042, 140...</td>\n",
       "      <td>TNJDM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[2, 9404, 2649, 7878, 12978, 12668, 8025, 9789...</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[2, 11167, 7306, 16377, 19686, 15270, 19615, 1...</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input_ids disease_group\n",
       "0   [2, 18875, 9387, 16079, 13985, 7126, 16450, 66...      Inactive\n",
       "1   [2, 9217, 14319, 14806, 11632, 7716, 3495, 726...      Inactive\n",
       "2   [2, 5788, 15343, 12186, 7590, 8735, 3857, 1701...         TNJDM\n",
       "3   [2, 915, 4305, 11429, 9572, 15371, 1001, 241, ...      Inactive\n",
       "4   [2, 16736, 15270, 12350, 744, 4331, 3174, 4155...         TNJDM\n",
       "..                                                ...           ...\n",
       "95  [2, 5147, 11990, 17364, 11054, 13685, 5365, 15...         TNJDM\n",
       "96  [2, 10643, 10673, 6331, 5689, 15032, 3462, 162...      Inactive\n",
       "97  [2, 5301, 1815, 18787, 14578, 12978, 7042, 140...         TNJDM\n",
       "98  [2, 9404, 2649, 7878, 12978, 12668, 8025, 9789...      Inactive\n",
       "99  [2, 11167, 7306, 16377, 19686, 15270, 19615, 1...            HC\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = subset.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911089f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_training_args = TrainingArguments(\n",
    "      output_dir=\"quick_test_output\",\n",
    "      num_train_epochs=1,              # just 3 epochs for quick test\n",
    "      learning_rate=5e-5,\n",
    "      per_device_train_batch_size=8,\n",
    "      per_device_eval_batch_size=8,\n",
    "      warmup_steps=50,\n",
    "      weight_decay=0.01,\n",
    "      logging_steps=10,\n",
    "      eval_strategy=\"no\",        # no eval for quick test\n",
    "      save_strategy=\"no\",              # don't save for quick test\n",
    "      remove_unused_columns=False,\n",
    "  )\n",
    "\n",
    "  # Quick classifier test\n",
    "quick_classifier = Classifier(\n",
    "      classifier=\"cell\",\n",
    "      cell_state_dict={\"state_key\": \"disease_group\", \"states\": \"all\"},\n",
    "      max_ncells=100,                  # use only 100 cells\n",
    "      training_args=quick_training_args.to_dict(),\n",
    "      freeze_layers=8,                 # freeze more layers for speed\n",
    "      num_crossval_splits=1,           # no cross-validation\n",
    "      forward_batch_size=8,\n",
    "      nproc=2,\n",
    "      ngpu=1\n",
    "  )\n",
    "\n",
    "os.makedirs(\"quick_test_prepared\", exist_ok=True)\n",
    "os.makedirs(\"quick_test_results\", exist_ok=True)\n",
    "\n",
    "  # Quick preparation and validation\n",
    "quick_classifier.prepare_data(\n",
    "      input_data_file=subset_path,\n",
    "      output_directory=\"quick_test_prepared\",\n",
    "      output_prefix=\"quick\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9214f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜quick_test_results/250613_geneformer_cellClassifier_quick_classifier/â€™: File exists\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]mkdir: cannot create directory â€˜quick_test_results/250613_geneformer_cellClassifier_quick_classifier/ksplit1â€™: File exists\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./Geneformer/gf-12L-95M-i4096 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/c4/home/tagashe/jdmanalysis/lib64/python3.11/site-packages/transformers/training_args.py:2029: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Validation split: 1/1 ******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtusharagashe1\u001b[0m (\u001b[33mtusharagashe1-university-of-california\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/c4/home/tagashe/jdmwork/wandb/run-20250613_165153-uqj2iyox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tusharagashe1-university-of-california/huggingface/runs/uqj2iyox' target=\"_blank\">quick_test_output</a></strong> to <a href='https://wandb.ai/tusharagashe1-university-of-california/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tusharagashe1-university-of-california/huggingface' target=\"_blank\">https://wandb.ai/tusharagashe1-university-of-california/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tusharagashe1-university-of-california/huggingface/runs/uqj2iyox' target=\"_blank\">https://wandb.ai/tusharagashe1-university-of-california/huggingface/runs/uqj2iyox</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/c4/home/tagashe/jdmwork/Geneformer/geneformer/collator_for_classification.py:668: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.385700</td>\n",
       "      <td>1.327843</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "index can't contain negative values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m quick_metrics = \u001b[43mquick_classifier\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./Geneformer/gf-12L-95M-i4096\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprepared_input_data_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquick_test_prepared/quick_labeled_train.dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mid_class_dict_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquick_test_prepared/quick_id_class_dict.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquick_test_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquick_classifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_hyperopt_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# no hyperopt for quick test\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mQuick test completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuick test metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquick_metrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/Geneformer/geneformer/classifier.py:817\u001b[39m, in \u001b[36mClassifier.validate\u001b[39m\u001b[34m(self, model_directory, prepared_input_data_file, id_class_dict_file, output_directory, output_prefix, split_id_dict, attr_to_split, attr_to_balance, gene_balance, max_trials, pval_threshold, save_eval_output, predict_eval, predict_trainer, n_hyperopt_trials, save_gene_split_datasets, debug_gene_split_datasets)\u001b[39m\n\u001b[32m    814\u001b[39m         iteration_num = iteration_num + \u001b[32m1\u001b[39m\n\u001b[32m    815\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mid_class_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpredict_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mksplit_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m results += [result]\n\u001b[32m    827\u001b[39m all_conf_mat = all_conf_mat + result[\u001b[33m\"\u001b[39m\u001b[33mconf_mat\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/Geneformer/geneformer/classifier.py:1322\u001b[39m, in \u001b[36mClassifier.evaluate_model\u001b[39m\u001b[34m(self, model, num_classes, id_class_dict, eval_data, predict, output_directory, output_prefix)\u001b[39m\n\u001b[32m   1320\u001b[39m \u001b[38;5;66;03m##### Evaluate the model #####\u001b[39;00m\n\u001b[32m   1321\u001b[39m labels = id_class_dict.keys()\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m y_pred, y_true, logits_list = \u001b[43meu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclassifier_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_batch_size\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m conf_mat, macro_f1, acc, roc_metrics = eu.get_metrics(\n\u001b[32m   1326\u001b[39m     y_pred, y_true, logits_list, num_classes, labels\n\u001b[32m   1327\u001b[39m )\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/Geneformer/geneformer/evaluation_utils.py:106\u001b[39m, in \u001b[36mclassifier_predict\u001b[39m\u001b[34m(model, classifier_type, evalset, forward_batch_size)\u001b[39m\n\u001b[32m    104\u001b[39m max_range = \u001b[38;5;28mmin\u001b[39m(i + forward_batch_size, evalset_len)\n\u001b[32m    105\u001b[39m batch_evalset = evalset.select([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, max_range)])\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m padded_batch = \u001b[43mpreprocess_classifier_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_evalset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evalset_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_name\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m padded_batch.set_format(\u001b[38;5;28mtype\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m input_data_batch = padded_batch[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/Geneformer/geneformer/evaluation_utils.py:55\u001b[39m, in \u001b[36mpreprocess_classifier_batch\u001b[39m\u001b[34m(cell_batch, max_len, label_name)\u001b[39m\n\u001b[32m     50\u001b[39m     example[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m     51\u001b[39m         example[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m] != gene_token_dict.get(\u001b[33m\"\u001b[39m\u001b[33m<pad>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m     ).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m example\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m padded_batch = \u001b[43mcell_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_label_example\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m padded_batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmanalysis/lib64/python3.11/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmanalysis/lib64/python3.11/site-packages/datasets/arrow_dataset.py:3079\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   3073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3074\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[32m   3075\u001b[39m         unit=\u001b[33m\"\u001b[39m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3076\u001b[39m         total=pbar_total,\n\u001b[32m   3077\u001b[39m         desc=desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3078\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m3079\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmanalysis/lib64/python3.11/site-packages/datasets/arrow_dataset.py:3501\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, try_original_type)\u001b[39m\n\u001b[32m   3499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[32m   3500\u001b[39m     _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3501\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3502\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3503\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmanalysis/lib64/python3.11/site-packages/datasets/arrow_dataset.py:3475\u001b[39m, in \u001b[36mDataset._map_single.<locals>.iter_outputs\u001b[39m\u001b[34m(shard_iterable)\u001b[39m\n\u001b[32m   3473\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3474\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[32m-> \u001b[39m\u001b[32m3475\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmanalysis/lib64/python3.11/site-packages/datasets/arrow_dataset.py:3398\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function\u001b[39m\u001b[34m(pa_inputs, indices, offset)\u001b[39m\n\u001b[32m   3396\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[32m   3397\u001b[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001b[32m-> \u001b[39m\u001b[32m3398\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmwork/Geneformer/geneformer/evaluation_utils.py:38\u001b[39m, in \u001b[36mpreprocess_classifier_batch.<locals>.pad_label_example\u001b[39m\u001b[34m(example)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpad_label_example\u001b[39m(example):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     example[label_name] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconstant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     example[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m] = np.pad(\n\u001b[32m     45\u001b[39m         example[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     46\u001b[39m         (\u001b[32m0\u001b[39m, max_len - \u001b[38;5;28mlen\u001b[39m(example[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m])),\n\u001b[32m     47\u001b[39m         mode=\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     48\u001b[39m         constant_values=gene_token_dict.get(\u001b[33m\"\u001b[39m\u001b[33m<pad>\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     49\u001b[39m     )\n\u001b[32m     50\u001b[39m     example[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m     51\u001b[39m         example[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m] != gene_token_dict.get(\u001b[33m\"\u001b[39m\u001b[33m<pad>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m     ).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmanalysis/lib64/python3.11/site-packages/numpy/lib/_arraypad_impl.py:757\u001b[39m, in \u001b[36mpad\u001b[39m\u001b[34m(array, pad_width, mode, **kwargs)\u001b[39m\n\u001b[32m    754\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33m`pad_width` must be of integral type.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    756\u001b[39m \u001b[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m pad_width = \u001b[43m_as_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mode):\n\u001b[32m    760\u001b[39m     \u001b[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[32m    761\u001b[39m     function = mode\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/jdmanalysis/lib64/python3.11/site-packages/numpy/lib/_arraypad_impl.py:526\u001b[39m, in \u001b[36m_as_pairs\u001b[39m\u001b[34m(x, ndim, as_index)\u001b[39m\n\u001b[32m    524\u001b[39m         x = x.ravel()  \u001b[38;5;66;03m# Ensure x[0], x[1] works\u001b[39;00m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m as_index \u001b[38;5;129;01mand\u001b[39;00m (x[\u001b[32m0\u001b[39m] < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x[\u001b[32m1\u001b[39m] < \u001b[32m0\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mindex can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt contain negative values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    527\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m ((x[\u001b[32m0\u001b[39m], x[\u001b[32m1\u001b[39m]),) * ndim\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m as_index \u001b[38;5;129;01mand\u001b[39;00m x.min() < \u001b[32m0\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: index can't contain negative values"
     ]
    }
   ],
   "source": [
    "quick_metrics = quick_classifier.validate(\n",
    "        model_directory=\"./Geneformer/gf-12L-95M-i4096\",\n",
    "        prepared_input_data_file=\"quick_test_prepared/quick_labeled_train.dataset\",\n",
    "        id_class_dict_file=\"quick_test_prepared/quick_id_class_dict.pkl\",\n",
    "        output_directory=\"quick_test_results\",\n",
    "        output_prefix=\"quick_classifier\",\n",
    "        n_hyperopt_trials=0,             # no hyperopt for quick test\n",
    "    )\n",
    "    \n",
    "print(\"Quick test completed!\")\n",
    "print(f\"Quick test metrics: {quick_metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jdmanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
